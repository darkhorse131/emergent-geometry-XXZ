{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e9403e-48f6-4d4c-8b1e-7ae83e6c6ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [code]\n",
    "import importlib, dmrg_runner, validate_jewel\n",
    "importlib.reload(dmrg_runner)\n",
    "importlib.reload(validate_jewel)\n",
    "from validate_jewel import run_and_evaluate_delta\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json\n",
    "\n",
    "print(\"--- DMRG Simulation for PRL ---\")\n",
    "print(\"NOTE: This script runs multiple, larger simulations and will take significant time (potentially hours or days).\")\n",
    "\n",
    "# 1) Parameters for a “PRL-Grade” run\n",
    "L_values     = [64, 96] \n",
    "bond_dims    = [64, 128, 256, 512] \n",
    "cutoffs      = [1e-10] * len(bond_dims) \n",
    "n_sweeps     = 12 \n",
    "tol          = 1e-8 \n",
    "fit_r_min    = 3 \n",
    "fit_r_max_fac = 0.5 \n",
    "outdir       = \"prl_jewel_runs\"\n",
    "\n",
    "os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "results_delta1 = {}\n",
    "results_delta2 = {}\n",
    "summaries_delta1 = {}\n",
    "summaries_delta2 = {}\n",
    "\n",
    "# 2) Loop over system sizes and run simulations\n",
    "for L in L_values:\n",
    "    print(f\"\\n--- Starting Simulations for L = {L} ---\")\n",
    "    r_max = L // 2\n",
    "    r_max_fit = int(r_max * fit_r_max_fac) \n",
    "    print(f\"L={L}, Max bond_dim={max(bond_dims)}, Sweeps={n_sweeps}\")\n",
    "    print(f\"MI will be calculated up to r={r_max}. Fits will use r in [{fit_r_min}, ~{r_max_fit}].\")\n",
    "\n",
    "    # --- Run Δ=1.0 (Critical) ---\n",
    "    print(f\"\\nRunning Δ=1.0 for L={L}...\")\n",
    "    props1, sum1 = run_and_evaluate_delta(\n",
    "        1.0,\n",
    "        L=L,\n",
    "        bond_dims_schedule=bond_dims,\n",
    "        cutoffs_schedule=cutoffs,\n",
    "        n_sweeps=n_sweeps,\n",
    "        r_max_mi=r_max,\n",
    "        r_max_corr=r_max,\n",
    "        fit_r_min=fit_r_min,\n",
    "        fit_r_max_factor=fit_r_max_fac,\n",
    "        output_dir=outdir\n",
    "        # run_label=f\"L{L}_delta1\" # REMOVED THIS LINE\n",
    "    )\n",
    "    results_delta1[L] = props1\n",
    "    summaries_delta1[L] = sum1\n",
    "\n",
    "    # --- Run Δ=2.0 (Gapped) ---\n",
    "    print(f\"\\nRunning Δ=2.0 for L={L}...\")\n",
    "    props2, sum2 = run_and_evaluate_delta(\n",
    "        2.0,\n",
    "        L=L,\n",
    "        bond_dims_schedule=bond_dims,\n",
    "        cutoffs_schedule=cutoffs,\n",
    "        n_sweeps=n_sweeps,\n",
    "        r_max_mi=r_max,\n",
    "        r_max_corr=r_max,\n",
    "        fit_r_min=fit_r_min,\n",
    "        fit_r_max_factor=fit_r_max_fac,\n",
    "        output_dir=outdir\n",
    "        # run_label=f\"L{L}_delta2\" # REMOVED THIS LINE\n",
    "    )\n",
    "    results_delta2[L] = props2\n",
    "    summaries_delta2[L] = sum2\n",
    "\n",
    "    # --- Convergence Check ---\n",
    "    print(f\"\\n--- Convergence Check for L = {L} ---\")\n",
    "    converged1 = summaries_delta1.get(L, {}).get('converged', 'Unknown')\n",
    "    variance1 = summaries_delta1.get(L, {}).get('var_val', np.nan)\n",
    "    print(f\"Δ=1.0: Converged = {converged1}, Variance = {variance1:.2e}\")\n",
    "    if not (converged1 is True):\n",
    "         print(f\"⚠️ WARNING: Δ=1.0 L={L} DID NOT CONVERGE or status unknown!\")\n",
    "\n",
    "    converged2 = summaries_delta2.get(L, {}).get('converged', 'Unknown')\n",
    "    variance2 = summaries_delta2.get(L, {}).get('var_val', np.nan)\n",
    "    print(f\"Δ=2.0: Converged = {converged2}, Variance = {variance2:.2e}\")\n",
    "    if not (converged2 is True):\n",
    "         print(f\"⚠️ WARNING: Δ=2.0 L={L} DID NOT CONVERGE or status unknown!\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "print(\"\\n--- All Simulations Finished ---\")\n",
    "\n",
    "# --- Save Summaries ---\n",
    "summary_file = os.path.join(outdir, \"all_summaries.json\")\n",
    "all_summaries = {'delta1': summaries_delta1, 'delta2': summaries_delta2}\n",
    "try:\n",
    "    with open(summary_file, 'w') as f:\n",
    "        json.dump(all_summaries, f, indent=4)\n",
    "    print(f\"Saved run summaries to {summary_file}\")\n",
    "except TypeError as e:\n",
    "    print(f\"Could not save full summary due to non-serializable data: {e}.\")\n",
    "\n",
    "# --- Analysis & Finite-Size Scaling (Example) ---\n",
    "print(\"\\n--- Fit Exponents (X) vs 1/L for Δ=1.0 ---\")\n",
    "X_values = []\n",
    "L_inv_values = []\n",
    "for L in L_values:\n",
    "    X = summaries_delta1.get(L, {}).get('fit_X_mi', np.nan)\n",
    "    if not np.isnan(X):\n",
    "        X_values.append(X)\n",
    "        L_inv_values.append(1.0/L)\n",
    "        print(f\"L = {L:3d}, 1/L = {1.0/L:.4f}, X = {X:.3f} ± {summaries_delta1[L].get('fit_X_mi_err', 0):.3f}\")\n",
    "\n",
    "# --- Plotting ---\n",
    "print(\"\\nGenerating plots...\")\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6), constrained_layout=True)\n",
    "colors = plt.cm.viridis(np.linspace(0, 0.8, len(L_values)))\n",
    "markers = ['o', '^', 'P', 'X']\n",
    "\n",
    "# --- Left: I(r) log–log ---\n",
    "for i, L in enumerate(L_values):\n",
    "    if L in results_delta1 and results_delta1[L]:\n",
    "        r1, I1 = results_delta1[L]['r_values_mi'], results_delta1[L]['I_r_values']\n",
    "        ax1.loglog(r1, I1, marker=markers[i % len(markers)], ls='-', color=colors[i], label=f'Δ=1.0 (L={L})')\n",
    "    if L in results_delta2 and results_delta2[L] and L == max(L_values):\n",
    "        r2, I2 = results_delta2[L]['r_values_mi'], results_delta2[L]['I_r_values']\n",
    "        ax1.loglog(r2, I2, 's--', color='orange', label=f'Δ=2.0 (L={L})')\n",
    "\n",
    "if max(L_values) in results_delta1 and results_delta1[max(L_values)]:\n",
    "    r_ref = np.array(results_delta1[max(L_values)]['r_values_mi'], dtype=float)\n",
    "    ref_idx = min(fit_r_min - 1, len(results_delta1[max(L_values)]['I_r_values']) - 1)\n",
    "    I_ref_start = results_delta1[max(L_values)]['I_r_values'][ref_idx] \n",
    "    r_ref_start = r_ref[ref_idx]\n",
    "    C_ref = I_ref_start * (r_ref_start**2)\n",
    "    ax1.loglog(r_ref, C_ref * r_ref**(-2), 'k:', label=r'$I(r) \\propto r^{-2}$ ref', alpha=0.7)\n",
    "\n",
    "ax1.set_title(\"Mutual Information $I(r)$\")\n",
    "ax1.set_xlabel(\"Distance $r$\")\n",
    "ax1.set_ylabel(\"$I(r)$\")\n",
    "ax1.grid(True, which=\"both\", ls=\"--\", alpha=0.5)\n",
    "ax1.legend()\n",
    "\n",
    "# --- Right: d_E(r) linear ---\n",
    "for i, L in enumerate(L_values):\n",
    "    if L in results_delta1 and results_delta1[L]:\n",
    "        r1, dE1 = results_delta1[L]['r_values_mi'], results_delta1[L]['d_E_r_values']\n",
    "        ax2.plot(r1, dE1, marker=markers[i % len(markers)], ls='-', color=colors[i], label=f'Δ=1.0 (L={L})')\n",
    "    if L in results_delta2 and results_delta2[L] and L == max(L_values):\n",
    "        r2, dE2 = results_delta2[L]['r_values_mi'], results_delta2[L]['d_E_r_values']\n",
    "        ax2.plot(r2, dE2, 's--', color='orange', label=f'Δ=2.0 (L={L})')\n",
    "\n",
    "if max(L_values) in results_delta1 and results_delta1[max(L_values)]:\n",
    "    r_ref = np.array(results_delta1[max(L_values)]['r_values_mi'], dtype=float)\n",
    "    k_ref = summaries_delta1.get(max(L_values), {}).get('fit_k_de', 1.0)\n",
    "    ax2.plot(r_ref, k_ref * r_ref, 'k:', label=f'$d_E = {k_ref:.2f} \\\\times r$ ref', alpha=0.7)\n",
    "\n",
    "ax2.set_title(\"Emergent Distance $d_E(r)$\") \n",
    "ax2.set_xlabel(\"Distance $r$\")\n",
    "ax2.set_ylabel(\"$d_E(r)$\")\n",
    "ax2.grid(True, ls=\"--\", alpha=0.5)\n",
    "ax2.legend()\n",
    "\n",
    "plot_file = os.path.join(outdir, \"prl_jewel_plot_finite_size.png\")\n",
    "plt.savefig(plot_file, dpi=300)\n",
    "print(f\"Saved plot to {plot_file}\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n--- Recommendations for Next Steps ---\")\n",
    "print(\"1. Analyze Convergence & Tolerance.\")\n",
    "print(\"2. Check File Outputs: Make sure your runs aren't overwriting each other's data!\")\n",
    "print(\"3. Finite-Size Extrapolation.\")\n",
    "print(\"4. Truncation Error Checks.\")\n",
    "print(\"5. Supplemental Material.\")\n",
    "\n",
    "# ==============================================================================\n",
    "# NEW CODE BLOCK: SAVE THE COMPLETE, RAW DATA TO CSV\n",
    "# Add this to the end of your existing, working Jupyter cell.\n",
    "# ==============================================================================\n",
    "\n",
    "# Define the full, absolute path for the output directory\n",
    "output_directory = \"/Users/beautrudel/Desktop/Projects/Project-Photon/Jewel_Test/PRL_Golden_Run\"\n",
    "# Ensure the directory exists\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "print(f\"\\n--- Saving complete data sets to: {output_directory} ---\")\n",
    "\n",
    "# --- Save data for Delta = 1.0 runs ---\n",
    "for L, data in results_delta1.items():\n",
    "    if data: # Check if data dictionary is not empty\n",
    "        output_filename = os.path.join(output_directory, f\"paper1_final_data_L{L}_delta1.0.csv\")\n",
    "        # Extract the arrays we need for the plot\n",
    "        df = pd.DataFrame({\n",
    "            'r': data['r_values_mi'],\n",
    "            'I(r)': data['I_r_values'],\n",
    "            'd_E(r)': data['d_E_r_values']\n",
    "        })\n",
    "        df.to_csv(output_filename, index=False, float_format='%.10e')\n",
    "        print(f\"--> Successfully saved: {output_filename}\")\n",
    "\n",
    "# --- Save data for Delta = 2.0 runs ---\n",
    "for L, data in results_delta2.items():\n",
    "    if data: # Check if data dictionary is not empty\n",
    "        output_filename = os.path.join(output_directory, f\"paper1_final_data_L{L}_delta2.0.csv\")\n",
    "        df = pd.DataFrame({\n",
    "            'r': data['r_values_mi'],\n",
    "            'I(r)': data['I_r_values'],\n",
    "            'd_E(r)': data['d_E_r_values']\n",
    "        })\n",
    "        df.to_csv(output_filename, index=False, float_format='%.10e')\n",
    "        print(f\"--> Successfully saved: {output_filename}\")\n",
    "\n",
    "print(\"\\n--- Raw data export complete. ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ed351c-e120-447d-bd3b-bcdf010f10e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "def generate_figure_with_inset_v2():\n",
    "    \"\"\"\n",
    "    Creates the main 2-panel figure with the inset shifted to the right.\n",
    "    \"\"\"\n",
    "    # --- Load Data ---\n",
    "    data_path = \"/Users/beautrudel/Desktop/Projects/Project-Photon/Jewel_Test/PRL_Golden_Run\"\n",
    "\n",
    "    try:\n",
    "        df_l64_d1 = pd.read_csv(os.path.join(data_path, 'paper1_final_data_L64_delta1.0.csv'))\n",
    "        df_l64_d2 = pd.read_csv(os.path.join(data_path, 'paper1_final_data_L64_delta2.0.csv'))\n",
    "        df_l96_d1 = pd.read_csv(os.path.join(data_path, 'paper1_final_data_L96_delta1.0.csv'))\n",
    "        df_l96_d2 = pd.read_csv(os.path.join(data_path, 'paper1_final_data_L96_delta2.0.csv'))\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: {e}. Make sure the path in the 'data_path' variable is correct.\")\n",
    "        return\n",
    "\n",
    "    # --- Calculate Emergent Distance and K_0 ---\n",
    "    for df in [df_l96_d1, df_l64_d1, df_l96_d2, df_l64_d2]:\n",
    "        df['d_E_raw'] = 1.0 / np.sqrt(df['I(r)'])\n",
    "\n",
    "    calib_data = df_l96_d1[(df_l96_d1['r'] >= 10) & (df_l96_d1['r'] <= 45)]\n",
    "    slope_calib, _ = np.polyfit(calib_data['r'], calib_data['d_E_raw'], 1)\n",
    "    K0 = 1.0 / slope_calib\n",
    "\n",
    "    # --- Generate Main Plot ---\n",
    "    plt.style.use('default')\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5.5))\n",
    "    plt.rcParams['font.family'] = 'serif'\n",
    "    colors = {'l96_d1': '#2ca02c', 'l64_d1': '#9467bd', 'l96_d2': '#ff7f0e', 'l64_d2': '#d62728'}\n",
    "\n",
    "    # Panel (a): Mutual Information\n",
    "    ax1.loglog(df_l96_d1['r'], df_l96_d1['I(r)'], '^-', markersize=5, color=colors['l96_d1'], label='$\\Delta=1.0$ (L=96)')\n",
    "    ax1.loglog(df_l64_d1['r'], df_l64_d1['I(r)'], 'o-', markersize=5, color=colors['l64_d1'], label='$\\Delta=1.0$ (L=64)')\n",
    "    ax1.loglog(df_l96_d2['r'], df_l96_d2['I(r)'], 's--', markersize=5, color=colors['l96_d2'], label='$\\Delta=2.0$ (L=96)')\n",
    "    ax1.loglog(df_l64_d2['r'], df_l64_d2['I(r)'], 'x--', markersize=5, color=colors['l64_d2'], label='$\\Delta=2.0$ (L=64)')\n",
    "    r_ref = np.logspace(np.log10(5), np.log10(50), 100)\n",
    "    ax1.plot(r_ref, (K0**-2) * r_ref**-2, 'k:', label='$I(r) \\propto r^{-2}$ ref')\n",
    "    ax1.set(xlabel='Distance r', ylabel='Mutual Information $I(r)$', title='(a) Mutual Information')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, which=\"both\", ls=\"--\", alpha=0.5)\n",
    "\n",
    "    # Panel (b): Emergent Distance\n",
    "    ax2.plot(df_l96_d1['r'], K0 * df_l96_d1['d_E_raw'], '^-', markersize=5, color=colors['l96_d1'])\n",
    "    ax2.plot(df_l64_d1['r'], K0 * df_l64_d1['d_E_raw'], 'o-', markersize=5, color=colors['l64_d1'])\n",
    "    ax2.plot(df_l96_d2['r'], K0 * df_l96_d2['d_E_raw'], 's--', markersize=5, color=colors['l96_d2'])\n",
    "    ax2.plot(df_l64_d2['r'], K0 * df_l64_d2['d_E_raw'], 'x--', markersize=5, color=colors['l64_d2'])\n",
    "    r_ref_linear = np.array([0, 50])\n",
    "    ax2.plot(r_ref_linear, r_ref_linear, 'k:', label='$d_E(r) = r$ ref')\n",
    "    ax2.set(xlabel='Distance r', ylabel='Emergent Distance $d_E(r)$', title='(b) Emergent Distance')\n",
    "    max_y = max((K0 * df_l96_d2['d_E_raw']).max(), (K0 * df_l64_d2['d_E_raw']).max())\n",
    "    ax2.set_xlim(0, 50)\n",
    "    ax2.set_ylim(0, max_y * 1.05)\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, which=\"both\", ls=\"--\", alpha=0.5)\n",
    "\n",
    "    # --- THIS IS THE MODIFIED INSET ---\n",
    "    # The first coordinate is changed from 0.45 to 0.52 to shift it right.\n",
    "    ax_inset = ax2.inset_axes([0.52, 0.1, 0.45, 0.4]) # [left, bottom, width, height]\n",
    "    ax_inset.plot(df_l64_d1['r'], K0 * df_l64_d1['d_E_raw'], 'o-', markersize=4, color=colors['l64_d1'])\n",
    "    ax_inset.plot(df_l64_d2['r'], K0 * df_l64_d2['d_E_raw'], 'x--', markersize=4, color=colors['l64_d2'])\n",
    "    ax_inset.plot(r_ref_linear, r_ref_linear, 'k:')\n",
    "    ax_inset.set_title('Zoom: $L=64$', fontsize=10)\n",
    "    ax_inset.set_xlim(0, 40)\n",
    "    max_y_inset = (K0 * df_l64_d2[df_l64_d2['r']<=40]['d_E_raw']).max()\n",
    "    ax_inset.set_ylim(0, max_y_inset * 1.1)\n",
    "    ax_inset.grid(True, which=\"both\", ls=\"--\", alpha=0.3)\n",
    "\n",
    "    # --- Save Figure ---\n",
    "    fig.tight_layout()\n",
    "    output_filename = 'figure_1_with_inset_v2.png'\n",
    "    plt.savefig(output_filename, dpi=300)\n",
    "    print(f\"\\nPlot saved successfully as '{output_filename}'\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    generate_figure_with_inset_v2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7fc956-6d92-4cf2-87be-767c4159db82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "def generate_exponent_drift_plot():\n",
    "    \"\"\"\n",
    "    Creates a plot showing the fitted exponent X as a function of the\n",
    "    starting point of the fit window, r_min.\n",
    "    \"\"\"\n",
    "    # --- Load Data ---\n",
    "    data_path = \"/Users/beautrudel/Desktop/Projects/Project-Photon/Jewel_Test/PRL_Golden_Run\"\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(os.path.join(data_path, 'paper1_final_data_L96_delta1.0.csv'))\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: {e}. Make sure the path in the 'data_path' variable is correct.\")\n",
    "        return\n",
    "\n",
    "    # --- Define Fit Function ---\n",
    "    def power_law(r, C, X):\n",
    "        return C * r**(-X)\n",
    "\n",
    "    # --- Iterate through fit windows ---\n",
    "    r_min_values = range(2, 31) # Fit windows will start from r=2 up to r=30\n",
    "    exponents = []\n",
    "    errors = []\n",
    "\n",
    "    for r_min in r_min_values:\n",
    "        r_max = 45 # Keep the end of the fit window fixed\n",
    "        fit_data = df[(df['r'] >= r_min) & (df['r'] <= r_max)]\n",
    "\n",
    "        if len(fit_data) < 3: # Need at least 3 points to fit\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            params, cov = curve_fit(power_law, fit_data['r'], fit_data['I(r)'], p0=[1.0, 2.0])\n",
    "            X_val = params[1]\n",
    "            X_err = np.sqrt(np.diag(cov))[1]\n",
    "            exponents.append(X_val)\n",
    "            errors.append(X_err)\n",
    "        except RuntimeError:\n",
    "            # If fit fails, append NaN or skip\n",
    "            exponents.append(np.nan)\n",
    "            errors.append(np.nan)\n",
    "\n",
    "    # Filter out failed fits for plotting\n",
    "    valid_indices = ~np.isnan(exponents)\n",
    "    plot_rmin = np.array(r_min_values)[valid_indices]\n",
    "    plot_exponents = np.array(exponents)[valid_indices]\n",
    "    plot_errors = np.array(errors)[valid_indices]\n",
    "\n",
    "\n",
    "    # --- Generate Plot ---\n",
    "    plt.style.use('default')\n",
    "    fig, ax = plt.subplots(figsize=(8, 5))\n",
    "    plt.rcParams['font.family'] = 'serif'\n",
    "\n",
    "    ax.errorbar(plot_rmin, plot_exponents, yerr=plot_errors, fmt='o-', capsize=4, label='Fitted Exponent $X$')\n",
    "    \n",
    "    # Add horizontal line for the ideal X=2 case\n",
    "    ax.axhline(2.0, color='k', linestyle='--', label='$X=2$ (Ideal Euclidean Limit)')\n",
    "    \n",
    "    # Add horizontal lines for the observed range\n",
    "    ax.axhline(1.5, color='r', linestyle=':', alpha=0.7, label='$X \\\\approx 1.5$ (Long-distance fit)')\n",
    "\n",
    "\n",
    "    # --- Final Touches ---\n",
    "    ax.set_xlabel('Start of Fitting Window, $r_\\mathrm{min}$')\n",
    "    ax.set_ylabel('Fitted Information Exponent, $X$')\n",
    "    ax.set_title('Exponent Drift vs. Fitting Window ($L=96, \\Delta=1.0$)')\n",
    "    ax.legend()\n",
    "    ax.grid(True, which=\"both\", ls=\"--\", alpha=0.5)\n",
    "    ax.set_xticks(range(2, 31, 2)) # Set x-axis ticks to be integers\n",
    "    \n",
    "    # --- Save Figure ---\n",
    "    fig.tight_layout()\n",
    "    output_filename = 'exponent_vs_fit_window.png'\n",
    "    plt.savefig(output_filename, dpi=300)\n",
    "    print(f\"\\nPlot saved successfully as '{output_filename}'\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    generate_exponent_drift_plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
